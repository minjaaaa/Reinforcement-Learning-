# ğŸƒ Blackjack â€“ TD Methods (SARSA & Q-learning)

Ovaj repozitorijum sadrÅ¾i implementaciju **Blackjack** problema (Gymâ€‘style okruÅ¾enje) sa fokusom na **Temporal Difference (TD)** metode uÄenja, konkretno **SARSA** i **Qâ€‘learning**. Projekat je namenjen uÄenju i eksperimentisanju sa RL algoritmima na klasiÄnom kartiÄnom problemu.

---

##  SadrÅ¾aj projekta

* Implementacija Blackjack okruÅ¾enja (karte, Å¡pil, pravila)
* Definicija stanja, akcija i politika
* **SARSA (onâ€‘policy TD control)**
* **Qâ€‘learning (offâ€‘policy TD control)**
* Vizualizacija nauÄenih politika
* PoreÄ‘enje ponaÅ¡anja algoritama

Glavni notebook:

* `blackjack_TD_methods.ipynb`

---

## Opis problema â€“ Blackjack

Cilj agenta je da nauÄi optimalnu politiku igranja Blackjacka:

* **Stanja (State)** tipiÄno ukljuÄuju:

  * Trenutni zbir karata igraÄa
  * Vidljivu kartu dilera
  * Informaciju da li igraÄ ima *usable ace*

* **Akcije (Actions)**:

  * `HIT` â€“ povuci joÅ¡ jednu kartu
  * `HOLD / STAND` â€“ zavrÅ¡i potez

* **Nagrade (Rewards)**:

  * Pobeda: `+1`
  * Poraz: `-1`
  * NereÅ¡eno: `0`

Epizoda se zavrÅ¡ava kada igraÄ *bustâ€‘uje*, stane, ili se igra zavrÅ¡i poreÄ‘enjem sa dilerom.

---

## KoriÅ¡Ä‡eni algoritmi

### SARSA (Stateâ€“Actionâ€“Rewardâ€“Stateâ€“Action)

* **Onâ€‘policy** TD metoda
* UÄenje se vrÅ¡i na osnovu politike koja se trenutno izvrÅ¡ava

Karakteristike:

* Stabilnije ponaÅ¡anje
* Konzervativnija politika

---

### Qâ€‘learning

* **Offâ€‘policy** TD metoda
* UÄi optimalnu politiku nezavisno od ponaÅ¡ajne

Karakteristike:

* Agresivnije uÄenje
* BrÅ¾e konvergira ka optimalnoj politici

---

## Vizualizacija politika

Nakon uÄenja, politike se vizualizuju u obliku **heatmapa / tabela** koje prikazuju:

* Kada je optimalno `HIT`
* Kada je optimalno `HOLD`

Odvojeno za:

* Stanja sa *usable ace*
* Stanja bez *usable ace*

Ovo omoguÄ‡ava intuitivno poreÄ‘enje sa poznatim optimalnim Blackjack strategijama.

---

## Pokretanje projekta

1. Kloniraj repozitorijum
2. Pokreni Jupyter Notebook:

```bash
jupyter notebook blackjack_TD_methods.ipynb
```

3. IzvrÅ¡avaj Ä‡elije redom i posmatraj uÄenje i politike

---

## Tehnologije

* Python 3
* NumPy
* Matplotlib
* Jupyter Notebook

---

## Cilj projekta

Ovaj projekat je edukativnog karaktera i ima za cilj:

* Razumevanje razlike izmeÄ‘u **onâ€‘policy** i **offâ€‘policy** TD metoda
* Prakticno uÄenje Reinforcement Learningâ€‘a
* Analizu ponaÅ¡anja algoritama na jednostavnom, ali nelinearnom problemu

---

## Napomene

* Zarad ispravne konvergencije finalne politike koristio se majorty vote akcija u svim stanjima za nekoliko politika
* Pravila su promenjena za rad sa realnim (koliko toliko) BJ pravilima
* Profesorovi plotovi nisu doradjivani i politike su izbrisane ali ostatak implementacije je tu
